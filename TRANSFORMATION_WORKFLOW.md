# Project Transformation Workflow
## From Academic Project to Professional Portfolio

**Goal**: Transform this scheduling simulator from a course project into a professional, impressive portfolio piece suitable for internship/research applications.

**Total Effort**: 16-23 hours of focused work
**Priority**: Execute Sprint 1 first (critical foundation), then prioritize based on time available

---

## ðŸ“‹ Executive Summary

### Current State
- âœ… Strong technical foundation (discrete-event simulation, 4 algorithms + 4 DPE variants)
- âœ… Well-organized code structure (5 clean files)
- âœ… Comprehensive testing (24 scenarios across 5 categories)
- âœ… Visualization capabilities (173 charts)
- âŒ Academic branding (COMP3821 references throughout)
- âŒ Missing professional documentation
- âŒ No testing infrastructure or CI/CD
- âŒ Limited accessibility (no CLI, configuration system)

### Target State
- ðŸŽ¯ Professional open-source research toolkit
- ðŸŽ¯ Publication-quality documentation
- ðŸŽ¯ Comprehensive test suite with CI/CD
- ðŸŽ¯ User-friendly CLI and configuration
- ðŸŽ¯ Research context with citations
- ðŸŽ¯ Portfolio-ready presentation

### Key Differentiation Points
1. **Systems Thinking**: Complete simulation infrastructure, not just algorithms
2. **Research Rigor**: 24 scenarios, systematic experimental design, Pareto analysis
3. **Software Engineering**: Clean architecture, testing, CI/CD, professional tooling
4. **Communication Skills**: Publication-quality visualizations, multi-audience docs
5. **Initiative**: Self-directed transformation beyond course requirements

---

## ðŸš€ Sprint 1: Foundation (CRITICAL - Execute First)
**Duration**: 2-3 hours
**Status**: MUST complete before any other work

### Phase 1: Academic Context Removal

#### Task 1.1: Remove COMP3821 References
**Files to modify** (6 files identified):
- `README.md` (lines 1, 3, 246)
- `scenarios.py` (lines 2, 13)
- `simple_simulator.py` (line 3)
- `algorithms.py` (line 2)
- `runner.py` (check for references)
- `visualizer.py` (check for references)

**Search and replace**:
```bash
# Find all references
grep -r "COMP3821\|3821\|comp3821\|Group 5" . --exclude-dir=.git --exclude-dir=.venv

# Replacements needed:
"COMP3821 Scheduling Simulator" â†’ "PySchedule: Real-Time Scheduling Research Toolkit"
"COMP3821 Project" â†’ "Scheduling Research Project"
"For COMP3821" â†’ [Remove entirely]
"Author: Group 5" â†’ "Author: [Your Name]"
"Date: November 2024" â†’ "Date: 2024"
```

#### Task 1.2: Project Rebranding
**New Identity**:
- **Name**: PySchedule (or PyScheduleRT)
- **Tagline**: "A discrete-event simulation framework for evaluating real-time scheduling algorithms"
- **License**: MIT License
- **Author**: Your name and professional attribution

**Actions**:
1. Update all file headers with new project name
2. Create consistent tagline across all files
3. Add LICENSE file (MIT recommended)
4. Update repository description

#### Task 1.3: Clean Repository Structure
```bash
# Verify no academic artifacts
ls -la results/
ls -la visualizations/

# Update .gitignore
echo "*.pyc" >> .gitignore
echo "__pycache__/" >> .gitignore
echo ".pytest_cache/" >> .gitignore
echo ".coverage" >> .gitignore
echo "htmlcov/" >> .gitignore
```

---

## ðŸ“š Sprint 2: Core Enhancement (Parallel Execution Possible)
**Duration**: 4-6 hours
**Priority**: High impact, moderate effort

### Phase 2: Professional Documentation

#### Task 2.1: README Overhaul
Create new structure:

```markdown
# PySchedule: Real-Time Scheduling Research Toolkit

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Build Status](badge-here)](workflow-link)

> A discrete-event simulation framework for evaluating real-time scheduling algorithms with priorities and deadlines.

## âœ¨ Features

- ðŸš€ **Discrete-event simulation engine** with event-driven architecture
- ðŸ“Š **8 scheduling algorithms**: SPT, EDF, Priority-First, DPE (Î±=0.3/0.5/0.7/0.9)
- ðŸŽ¯ **24 comprehensive test scenarios** spanning 5 categories
- ðŸ“ˆ **Publication-quality visualizations** (Gantt charts, heatmaps, Pareto frontiers)
- ðŸ”§ **Extensible architecture** for implementing custom algorithms
- ðŸ’» **CLI interface** for easy experimentation

## ðŸš€ Quick Start

### Installation
```bash
git clone https://github.com/yourusername/pyschedule.git
cd pyschedule
pip install -r requirements.txt
```

### Basic Usage
```python
from simple_simulator import Task, Priority
from algorithms import EDF_Scheduler

# Define tasks
tasks = [
    Task(1, arrival_time=0, processing_time=3, priority=Priority.HIGH, deadline=10),
    Task(2, arrival_time=1, processing_time=5, priority=Priority.LOW, deadline=15),
]

# Run simulation
scheduler = EDF_Scheduler(tasks, num_machines=2)
scheduler.run()
scheduler.print_results()
```

### Run Experiments
```bash
# Run all 168 experiments (24 scenarios Ã— 7 algorithms)
python3 runner.py

# Generate visualizations
python3 visualizer.py
```

## ðŸ“– Documentation

- [Architecture Guide](docs/ARCHITECTURE.md) - System design and components
- [API Reference](docs/API_REFERENCE.md) - Developer documentation
- [Research Background](docs/RESEARCH.md) - Theoretical foundation and citations
- [Contributing Guide](CONTRIBUTING.md) - How to contribute

## ðŸ”¬ Research Context

This toolkit implements and evaluates the **Dynamic Priority Elevation (DPE)** algorithm for real-time scheduling with mixed-priority workloads.

### Key Research Questions
- How can we balance fairness and efficiency in priority-based scheduling?
- What threshold (Î±) optimally prevents low-priority task starvation?
- How do different algorithms perform across diverse workload scenarios?

### Key Findings
- **Pareto Optimality**: Î± = 0.3, 0.5 achieve best fairness-efficiency trade-off (71.4% low-priority success)
- **Starvation Prevention**: Î± â‰¤ 0.5 prevents starvation in all test scenarios
- **Scenario Sensitivity**: Algorithm performance varies significantly by workload characteristics

## ðŸ“Š Experimental Design

### Algorithm Comparison
- **Baseline**: SPT, EDF, Priority-First
- **DPE Variants**: Î± âˆˆ {0.3, 0.5, 0.7, 0.9}

### Test Scenarios (24 total)
- **Basic** (4): Light Load, Heavy Load, Batch Arrival, Starvation Test
- **Challenge** (5): Long High-Priority, Mixed Deadlines, Cascading, etc.
- **Extreme** (5): Overload, Impossible Deadlines, Algorithm-specific failures
- **Advanced** (5): Deadline Clusters, Priority Imbalance, Variable Load
- **Specialized** (5): Deadline Gradient, Priority Waves, Tight Margins

### Metrics
- Deadline success rate (overall, by priority)
- Fairness score (high vs low priority balance)
- Average completion time
- Machine utilization

## ðŸ—ï¸ Architecture

```
PySchedule/
â”œâ”€â”€ simple_simulator.py    # Core simulation engine (Task, Machine, Event, Scheduler)
â”œâ”€â”€ algorithms.py          # All scheduling algorithm implementations
â”œâ”€â”€ scenarios.py           # 24 test scenarios across 5 categories
â”œâ”€â”€ runner.py              # Experiment execution and metrics
â”œâ”€â”€ visualizer.py          # Publication-quality visualizations
â”œâ”€â”€ results/               # Experimental results (CSV)
â””â”€â”€ visualizations/        # Generated charts (PNG)
```

## ðŸ¤ Contributing

Contributions welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

Potential contributions:
- New scheduling algorithms
- Additional test scenarios
- Performance optimizations
- Documentation improvements

## ðŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ðŸ“š Citation

If you use this toolkit in your research, please cite:

```bibtex
@software{pyschedule2024,
  title={PySchedule: Real-Time Scheduling Research Toolkit},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/pyschedule}
}
```

## ðŸ™ Acknowledgments

Inspired by real-time systems research and discrete-event simulation principles.

---

**Author**: Your Name
**Contact**: your.email@example.com
**Project Link**: https://github.com/yourusername/pyschedule
```

#### Task 2.2: Create docs/ARCHITECTURE.md

```markdown
# Architecture Guide

## System Overview

PySchedule is built on a discrete-event simulation architecture with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         User / Experiment Runner        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Scenarios     â”‚  (Test data definitions)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Algorithms    â”‚  (Scheduling policies)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Simulator     â”‚  (Discrete-event engine)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Metrics/Viz     â”‚  (Analysis & visualization)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. Discrete-Event Simulation Engine (`simple_simulator.py`)

**Purpose**: Event-driven simulation infrastructure

**Key Classes**:

#### Task
```python
@dataclass
class Task:
    id: int
    arrival_time: float
    processing_time: float
    priority: Priority
    deadline: float

    # Simulation state
    start_time: Optional[float] = None
    completion_time: Optional[float] = None
    machine_id: Optional[int] = None
```

**Responsibilities**:
- Store task parameters and constraints
- Calculate deadline pressure: Ï(t) = (t - t_arrival) / (deadline - t_arrival)
- Check deadline satisfaction

#### Machine
```python
@dataclass
class Machine:
    id: int
    available_at: float = 0.0
```

**Responsibilities**:
- Track machine availability
- Support parallel processing simulation

#### Event
```python
class Event:
    ARRIVAL = 1
    COMPLETION = 2
```

**Responsibilities**:
- Represent discrete simulation events
- Priority queue ordering (time-based)

#### Scheduler (Base Class)
```python
class Scheduler:
    def run(self):
        """Main simulation loop"""
        while self.event_queue:
            event = heapq.heappop(self.event_queue)
            self.current_time = event.time
            self.handle_event(event)

    @abstractmethod
    def select_task(self, ready_tasks):
        """Override to implement scheduling policy"""
        pass
```

**Responsibilities**:
- Manage event queue (priority queue by time)
- Process ARRIVAL and COMPLETION events
- Call algorithm-specific `select_task()` for scheduling decisions
- Track simulation state and metrics

**Extension Point**: Override `select_task()` to implement new algorithms

### 2. Scheduling Algorithms (`algorithms.py`)

All algorithms inherit from `Scheduler` and implement `select_task()`.

#### SPT (Shortest Processing Time)
- **Policy**: Always select task with minimum processing_time
- **Complexity**: O(n) per decision
- **Characteristics**: Optimizes makespan, ignores deadlines and priorities

#### EDF (Earliest Deadline First)
- **Policy**: Always select task with earliest deadline
- **Complexity**: O(n) per decision
- **Characteristics**: Optimal for single-machine without priorities

#### Priority-First
- **Policy**: Sort by (priority, deadline)
- **Complexity**: O(n) per decision
- **Characteristics**: Static priorities, can cause starvation

#### DPE (Dynamic Priority Elevation)
- **Policy**: Elevate low-priority tasks when Ï(t) > Î±
- **Complexity**: O(n) per decision (calculate pressure for all tasks)
- **Characteristics**: Adaptive, configurable Î± threshold

**Mathematical Formulation**:
```
effective_priority(task, t) = {
    HIGH,  if task.priority == HIGH or Ï(t) > Î±
    LOW,   otherwise
}

where Ï(t) = (t - t_arrival) / (deadline - t_arrival)
```

### 3. Test Scenarios (`scenarios.py`)

**Structure**:
```python
{
    'name': 'Scenario Name',
    'description': 'What it tests',
    'tasks': [Task(...), Task(...), ...],
    'num_machines': int
}
```

**Categories**:
1. **Basic** (4): Algorithm validation
2. **Challenge** (5): Algorithm differentiation
3. **Extreme** (5): Stress tests and edge cases
4. **Advanced** (5): Realistic multi-machine workloads
5. **Specialized** (5): Î±-sensitivity and specific patterns

### 4. Experiment Runner (`runner.py`)

**ExperimentRunner Class**:

```python
class ExperimentRunner:
    def run_experiment(self, scenario, algorithm_name, algorithm_class):
        """Run single experiment"""
        # 1. Create scheduler instance
        # 2. Run simulation
        # 3. Calculate metrics
        # 4. Return results

    def calculate_metrics(self, scheduler):
        """Calculate performance metrics"""
        return {
            'total_tasks': int,
            'tasks_met_deadline': int,
            'success_rate': float,
            'high_priority_success': float,
            'low_priority_success': float,
            'fairness_score': float,
            'avg_completion_time': float,
        }
```

**Metrics**:
- **Success Rate**: % tasks meeting deadline
- **Priority-Stratified Success**: Separate rates for HIGH/LOW
- **Fairness Score**: Balance between priority classes
- **Completion Time**: Average time from arrival to completion
- **Utilization**: Machine busy time / total simulation time

### 5. Visualization (`visualizer.py`)

**Visualization Types**:

1. **Gantt Charts** (168 total: 24 scenarios Ã— 7 algorithms)
   - Timeline view of task execution
   - Color-coded by priority
   - Deadline indicators

2. **Performance Heatmaps**
   - Scenario Ã— Algorithm matrix
   - Color intensity = success rate

3. **Î±-Sensitivity Analysis**
   - DPE performance vs Î± threshold
   - Identify optimal Î± values

4. **Pareto Frontier**
   - Trade-off: high-priority vs low-priority success
   - Identify Pareto-optimal algorithms

5. **Success Rate by Priority**
   - Grouped bar charts
   - Fairness comparison

## Data Flow

```
1. Scenario Definition (scenarios.py)
   â””â”€> Tasks created with arrival times, deadlines, priorities

2. Algorithm Selection (algorithms.py)
   â””â”€> Scheduler instantiated with tasks and machines

3. Simulation Execution (simple_simulator.py)
   â”œâ”€> Event Queue: Process ARRIVAL and COMPLETION events
   â”œâ”€> Ready Queue: Tasks available for scheduling
   â””â”€> Scheduling Decision: Call algorithm's select_task()

4. Metrics Calculation (runner.py)
   â””â”€> Analyze completion times, deadline satisfaction

5. Visualization (visualizer.py)
   â””â”€> Generate charts from metrics
```

## Performance Characteristics

### Time Complexity
- **Event Processing**: O(log E) per event (heap operations)
- **Scheduling Decision**: O(n) per decision (scan ready queue)
- **Total Simulation**: O(E log E + D Ã— n)
  - E = total events (2n for n tasks)
  - D = scheduling decisions (~n decisions)
  - Overall: O(nÂ² + n log n) = O(nÂ²)

### Space Complexity
- **Task Storage**: O(n)
- **Event Queue**: O(n)
- **Machine State**: O(m)
- **Total**: O(n + m)

### Scalability
- Efficient for 1-1000 tasks
- Parallel machine support (tested up to 10 machines)
- Memory-efficient (no history tracking beyond results)

## Extension Points

### Adding Custom Algorithms

1. **Inherit from Scheduler**:
```python
from simple_simulator import Scheduler

class MyAlgorithm(Scheduler):
    def select_task(self, ready_tasks):
        # Your scheduling logic here
        return selected_task
```

2. **Register in AVAILABLE_ALGORITHMS**:
```python
# algorithms.py
AVAILABLE_ALGORITHMS = {
    'MyAlgorithm': MyAlgorithm,
}
```

3. **Test with existing scenarios**:
```python
from runner import run_all_experiments
run_all_experiments()
```

### Adding Custom Scenarios

```python
# scenarios.py
def get_custom_scenarios():
    return [{
        'name': 'Custom Scenario',
        'description': 'Tests X behavior',
        'tasks': [
            Task(1, arrival=0, duration=5, priority=Priority.HIGH, deadline=10),
            # ... more tasks
        ],
        'num_machines': 2
    }]
```

### Adding Custom Metrics

```python
# runner.py
def calculate_custom_metric(scheduler):
    # Access scheduler.tasks, scheduler.machines
    # Compute your metric
    return metric_value
```

## Design Principles

1. **Separation of Concerns**
   - Simulation engine (simple_simulator.py)
   - Algorithm implementations (algorithms.py)
   - Test data (scenarios.py)
   - Execution (runner.py)
   - Visualization (visualizer.py)

2. **Open/Closed Principle**
   - Open for extension (new algorithms, scenarios)
   - Closed for modification (core engine stable)

3. **Single Responsibility**
   - Each class has one clear purpose
   - Task: data + basic calculations
   - Scheduler: simulation loop + event handling
   - Algorithm: scheduling policy only

4. **Dependency Inversion**
   - Algorithms depend on Scheduler abstraction
   - Runner depends on algorithm interface
   - No circular dependencies

## Testing Strategy

See [Testing Guide](TESTING.md) for comprehensive testing approach.

**Key Test Areas**:
- Unit tests for Task, Machine, Event classes
- Algorithm correctness tests
- Scenario validation tests
- Integration tests for full simulation
- Property-based tests for invariants

---

**Next**: See [API Reference](API_REFERENCE.md) for detailed API documentation.
```

#### Task 2.3: Create docs/API_REFERENCE.md

```markdown
# API Reference

Complete API documentation for PySchedule components.

## Core Classes

### Task

**Location**: `simple_simulator.py`

```python
@dataclass
class Task:
    id: int
    arrival_time: float
    processing_time: float
    priority: Priority
    deadline: float
    start_time: Optional[float] = None
    completion_time: Optional[float] = None
    machine_id: Optional[int] = None
```

**Parameters**:
- `id` (int): Unique task identifier
- `arrival_time` (float): Time when task becomes available
- `processing_time` (float): Time required to complete task (must be > 0)
- `priority` (Priority): Task priority (Priority.HIGH or Priority.LOW)
- `deadline` (float): Time by which task must complete (must be > arrival_time)
- `start_time` (Optional[float]): Set during simulation
- `completion_time` (Optional[float]): Set during simulation
- `machine_id` (Optional[int]): Machine assignment (set during simulation)

**Methods**:

#### `meets_deadline() -> bool`
Check if task completed before deadline.

**Returns**: True if completion_time â‰¤ deadline

**Example**:
```python
task = Task(1, arrival_time=0, processing_time=5, priority=Priority.HIGH, deadline=10)
# After simulation
if task.meets_deadline():
    print("Success!")
```

#### `deadline_pressure(current_time: float) -> float`
Calculate deadline pressure for DPE algorithm.

**Formula**: Ï(t) = (t - t_arrival) / (deadline - t_arrival)

**Parameters**:
- `current_time` (float): Current simulation time

**Returns**:
- `0.0` if task already started
- `inf` if deadline already passed
- Pressure ratio [0, 1] otherwise

**Example**:
```python
task = Task(1, arrival_time=0, processing_time=5, priority=Priority.LOW, deadline=10)
pressure = task.deadline_pressure(current_time=5)  # Returns 0.5
```

---

### Priority

**Location**: `simple_simulator.py`

```python
class Priority(Enum):
    HIGH = 1
    LOW = 2
```

**Usage**:
```python
from simple_simulator import Priority

high_priority_task = Task(1, 0, 5, Priority.HIGH, 10)
low_priority_task = Task(2, 0, 5, Priority.LOW, 15)
```

---

### Machine

**Location**: `simple_simulator.py`

```python
@dataclass
class Machine:
    id: int
    available_at: float = 0.0
```

**Methods**:

#### `is_idle(current_time: float) -> bool`
Check if machine is available at given time.

**Returns**: True if available_at â‰¤ current_time

---

### Event

**Location**: `simple_simulator.py`

```python
class Event:
    ARRIVAL = 1
    COMPLETION = 2

    def __init__(self, time: float, event_type: int, task: Task):
        self.time = time
        self.event_type = event_type
        self.task = task
```

**Event Types**:
- `Event.ARRIVAL`: Task becomes ready
- `Event.COMPLETION`: Task finishes execution

---

### Scheduler (Base Class)

**Location**: `simple_simulator.py`

```python
class Scheduler:
    def __init__(self, tasks: List[Task], num_machines: int):
        """Initialize scheduler with tasks and machines"""

    def run(self):
        """Execute simulation"""

    @abstractmethod
    def select_task(self, ready_tasks: List[Task]) -> Optional[Task]:
        """Override to implement scheduling policy"""
        pass

    def print_results(self):
        """Print simulation results"""
```

**Abstract Methods**:
- `select_task(ready_tasks)`: Must be overridden by subclasses

**Public Methods**:

#### `run()`
Execute the discrete-event simulation.

**Process**:
1. Process events from priority queue (ordered by time)
2. Handle ARRIVAL events: add task to ready queue
3. Handle COMPLETION events: free machine, schedule next task
4. Continue until all events processed

**Side Effects**: Updates task.start_time, task.completion_time, task.machine_id

**Example**:
```python
scheduler = EDF_Scheduler(tasks, num_machines=2)
scheduler.run()
```

#### `print_results()`
Print formatted simulation results to stdout.

**Output**:
- Task execution timeline
- Deadline satisfaction status
- Overall statistics

---

## Algorithm Implementations

### SPT_Scheduler

**Location**: `algorithms.py`

```python
class SPT_Scheduler(Scheduler):
    def select_task(self, ready_tasks):
        """Select task with shortest processing time"""
```

**Policy**: Greedy selection of minimum processing_time

**Complexity**: O(n) per decision

**Characteristics**:
- Optimizes average completion time
- Ignores deadlines and priorities
- Can cause deadline misses

**Example**:
```python
from algorithms import SPT_Scheduler

scheduler = SPT_Scheduler(tasks, num_machines=2)
scheduler.run()
```

---

### EDF_Scheduler

**Location**: `algorithms.py`

```python
class EDF_Scheduler(Scheduler):
    def select_task(self, ready_tasks):
        """Select task with earliest deadline"""
```

**Policy**: Greedy selection of minimum deadline

**Complexity**: O(n) per decision

**Characteristics**:
- Optimal for single-machine scheduling
- Ignores priorities
- Maximizes deadline satisfaction

**Example**:
```python
from algorithms import EDF_Scheduler

scheduler = EDF_Scheduler(tasks, num_machines=2)
scheduler.run()
```

---

### PriorityFirst_Scheduler

**Location**: `algorithms.py`

```python
class PriorityFirst_Scheduler(Scheduler):
    def select_task(self, ready_tasks):
        """Select by (priority, deadline) lexicographic order"""
```

**Policy**: Sort by (priority.value, deadline)

**Complexity**: O(n) per decision

**Characteristics**:
- Strict priority ordering
- EDF tie-breaking within priority class
- Can cause low-priority starvation

**Example**:
```python
from algorithms import PriorityFirst_Scheduler

scheduler = PriorityFirst_Scheduler(tasks, num_machines=2)
scheduler.run()
```

---

### DPE_Scheduler

**Location**: `algorithms.py`

```python
class DPE_Scheduler(Scheduler):
    def __init__(self, tasks, num_machines, alpha=0.7):
        """
        Dynamic Priority Elevation scheduler

        Parameters:
            tasks: List of Task objects
            num_machines: Number of parallel machines
            alpha: Elevation threshold (0.0 to 1.0)
        """
```

**Parameters**:
- `alpha` (float): Deadline pressure threshold for elevation
  - Î± â‰¤ 0.5: Conservative (prevents starvation)
  - Î± > 0.5: Aggressive (permits starvation)

**Policy**:
```python
effective_priority = HIGH if (original == HIGH or pressure > Î±) else LOW
select_task: min by (effective_priority, deadline)
```

**Complexity**: O(n) per decision (calculate pressure for all low-priority tasks)

**Characteristics**:
- Adaptive priority elevation
- Configurable fairness-efficiency trade-off
- Prevents starvation when Î± â‰¤ 0.5

**Example**:
```python
from algorithms import DPE_Scheduler

# Conservative (prevents starvation)
scheduler_conservative = DPE_Scheduler(tasks, num_machines=2, alpha=0.3)

# Balanced
scheduler_balanced = DPE_Scheduler(tasks, num_machines=2, alpha=0.5)

# Aggressive (permits starvation)
scheduler_aggressive = DPE_Scheduler(tasks, num_machines=2, alpha=0.9)

scheduler_conservative.run()
```

---

## Utility Functions

### get_all_algorithms()

**Location**: `algorithms.py`

```python
def get_all_algorithms() -> Dict[str, Type[Scheduler]]:
    """Get all available algorithms"""
```

**Returns**: Dictionary mapping algorithm names to Scheduler classes

**Example**:
```python
from algorithms import get_all_algorithms

algorithms = get_all_algorithms()
for name, algo_class in algorithms.items():
    print(f"Available: {name}")
```

---

### get_all_scenarios()

**Location**: `scenarios.py`

```python
def get_all_scenarios() -> List[Dict[str, Any]]:
    """Get all 24 test scenarios"""
```

**Returns**: List of scenario dictionaries with keys:
- `name` (str): Scenario identifier
- `description` (str): What the scenario tests
- `tasks` (List[Task]): Task definitions
- `num_machines` (int): Parallel machines

**Example**:
```python
from scenarios import get_all_scenarios

scenarios = get_all_scenarios()
print(f"Total scenarios: {len(scenarios)}")  # 24

for scenario in scenarios:
    print(f"{scenario['name']}: {scenario['description']}")
```

---

## Experiment Runner

### ExperimentRunner

**Location**: `runner.py`

```python
class ExperimentRunner:
    def run_experiment(self, scenario, algorithm_name, algorithm_class):
        """Run single experiment"""

    def calculate_metrics(self, scheduler):
        """Calculate performance metrics"""

    def export_to_csv(self, results, filename):
        """Export results to CSV"""
```

**Methods**:

#### `run_experiment(scenario, algorithm_name, algorithm_class)`

**Parameters**:
- `scenario` (dict): Scenario dictionary from get_all_scenarios()
- `algorithm_name` (str): Algorithm identifier
- `algorithm_class` (Type[Scheduler]): Scheduler class or factory

**Returns**: Dictionary with keys:
- `scenario` (str)
- `algorithm` (str)
- `total_tasks` (int)
- `tasks_met_deadline` (int)
- `success_rate` (float)
- `high_priority_success` (float)
- `low_priority_success` (float)
- `fairness_score` (float)
- `avg_completion_time` (float)

**Example**:
```python
from runner import ExperimentRunner
from scenarios import get_all_scenarios
from algorithms import EDF_Scheduler

runner = ExperimentRunner()
scenarios = get_all_scenarios()

result = runner.run_experiment(
    scenarios[0],
    'EDF',
    EDF_Scheduler
)
print(f"Success rate: {result['success_rate']:.1%}")
```

---

## Visualization

### SchedulingVisualizer

**Location**: `visualizer.py`

```python
class SchedulingVisualizer:
    def create_gantt_chart(self, scheduler, title, filename):
        """Create Gantt chart visualization"""
```

**Methods**:

#### `create_gantt_chart(scheduler, title, filename)`

**Parameters**:
- `scheduler` (Scheduler): Completed scheduler with results
- `title` (str): Chart title
- `filename` (str): Output PNG path

**Output**: Saves Gantt chart to file

**Example**:
```python
from visualizer import SchedulingVisualizer

viz = SchedulingVisualizer()
viz.create_gantt_chart(
    scheduler,
    title="EDF - Light Load",
    filename="visualizations/edf_light_load.png"
)
```

---

## Type Definitions

### Common Type Aliases

```python
from typing import List, Dict, Optional, Any

TaskList = List[Task]
ScenarioDict = Dict[str, Any]
MetricsDict = Dict[str, float]
AlgorithmRegistry = Dict[str, Type[Scheduler]]
```

---

## Constants

```python
# Priority values
Priority.HIGH.value = 1
Priority.LOW.value = 2

# Event types
Event.ARRIVAL = 1
Event.COMPLETION = 2

# Default parameters
DEFAULT_ALPHA = 0.7  # DPE threshold
DEFAULT_MACHINES = 2
```

---

## Error Handling

### Common Errors

**ValueError**: Invalid task parameters
```python
Task(1, arrival_time=10, processing_time=5, priority=Priority.HIGH, deadline=5)
# Raises: deadline must be > arrival_time
```

**TypeError**: Invalid priority type
```python
Task(1, 0, 5, priority="high", deadline=10)
# Raises: priority must be Priority enum
```

---

## Best Practices

### Creating Tasks
```python
# âœ… Good: Clear parameters
task = Task(
    id=1,
    arrival_time=0.0,
    processing_time=5.0,
    priority=Priority.HIGH,
    deadline=10.0
)

# âŒ Bad: Positional arguments hard to read
task = Task(1, 0, 5, Priority.HIGH, 10)
```

### Running Simulations
```python
# âœ… Good: Store result, check for errors
scheduler = EDF_Scheduler(tasks, num_machines=2)
scheduler.run()

if all(task.meets_deadline() for task in scheduler.tasks):
    print("All deadlines met!")

# âŒ Bad: No result validation
scheduler.run()
```

### Extending Algorithms
```python
# âœ… Good: Clear docstring, proper inheritance
class MyScheduler(Scheduler):
    """
    Custom scheduling algorithm.

    Policy: [Describe your policy]
    Complexity: O(?)
    """
    def select_task(self, ready_tasks):
        # Your logic
        return selected_task

# âŒ Bad: No documentation
class MyScheduler(Scheduler):
    def select_task(self, ready_tasks):
        return ready_tasks[0]
```

---

**Next**: See [Examples](../examples/) for usage tutorials.
```

### Phase 3: Code Quality Improvements (Parallel with Phase 2)

#### Task 2.4: Add Type Hints

**Files to enhance**:
```python
# simple_simulator.py
from typing import List, Optional, Tuple

class Scheduler:
    def __init__(self, tasks: List[Task], num_machines: int) -> None:
        ...

    def select_task(self, ready_tasks: List[Task]) -> Optional[Task]:
        ...

    def calculate_metrics(self) -> Dict[str, float]:
        ...

# algorithms.py
from typing import List, Optional

class DPE_Scheduler(Scheduler):
    def __init__(self, tasks: List[Task], num_machines: int, alpha: float = 0.7) -> None:
        ...
```

#### Task 2.5: Improve Error Handling

```python
# simple_simulator.py
@dataclass
class Task:
    def __post_init__(self):
        """Validate task parameters"""
        if self.processing_time <= 0:
            raise ValueError(f"processing_time must be > 0, got {self.processing_time}")
        if self.deadline <= self.arrival_time:
            raise ValueError(f"deadline must be > arrival_time ({self.deadline} <= {self.arrival_time})")
        if not isinstance(self.priority, Priority):
            raise TypeError(f"priority must be Priority enum, got {type(self.priority)}")

class Scheduler:
    def __init__(self, tasks: List[Task], num_machines: int):
        if not tasks:
            raise ValueError("tasks list cannot be empty")
        if num_machines < 1:
            raise ValueError(f"num_machines must be >= 1, got {num_machines}")
        # ... existing code
```

#### Task 2.6: Enhanced Docstrings

Use Google-style docstrings:
```python
def deadline_pressure(self, current_time: float) -> float:
    """Calculate deadline pressure for DPE algorithm.

    Deadline pressure represents the urgency of scheduling a task
    based on time elapsed versus time available until deadline.

    Args:
        current_time: Current simulation time

    Returns:
        Deadline pressure ratio:
            - 0.0 if task already started
            - inf if deadline already passed
            - Value in [0, 1] representing urgency otherwise

    Examples:
        >>> task = Task(1, arrival_time=0, processing_time=5,
        ...             priority=Priority.LOW, deadline=10)
        >>> task.deadline_pressure(5)
        0.5
        >>> task.deadline_pressure(10)
        inf
    """
```

---

## ðŸ§ª Sprint 3: Quality Assurance (6-8 hours)
**Priority**: High impact, time-intensive

### Phase 4: Testing Infrastructure

#### Task 3.1: Create Test Suite

**Directory structure**:
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py              # Pytest fixtures
â”œâ”€â”€ test_task.py             # Task class tests
â”œâ”€â”€ test_machine.py          # Machine tests
â”œâ”€â”€ test_event.py            # Event tests
â”œâ”€â”€ test_scheduler.py        # Scheduler base class
â”œâ”€â”€ test_algorithms.py       # Algorithm correctness
â”œâ”€â”€ test_scenarios.py        # Scenario validation
â”œâ”€â”€ test_integration.py      # End-to-end tests
â””â”€â”€ test_metrics.py          # Metrics calculation
```

**Sample tests**:

```python
# tests/test_task.py
import pytest
from simple_simulator import Task, Priority

def test_task_creation():
    """Test basic task creation"""
    task = Task(1, arrival_time=0, processing_time=5,
                priority=Priority.HIGH, deadline=10)
    assert task.id == 1
    assert task.meets_deadline() == False  # Not yet completed

def test_task_deadline_validation():
    """Test deadline validation"""
    with pytest.raises(ValueError):
        Task(1, arrival_time=10, processing_time=5,
             priority=Priority.HIGH, deadline=5)  # Invalid: deadline < arrival

def test_deadline_pressure_calculation():
    """Test deadline pressure formula"""
    task = Task(1, arrival_time=0, processing_time=5,
                priority=Priority.LOW, deadline=10)

    assert task.deadline_pressure(0) == 0.0  # At arrival
    assert task.deadline_pressure(5) == 0.5  # Halfway
    assert task.deadline_pressure(10) == float('inf')  # Past deadline

def test_deadline_satisfaction():
    """Test deadline checking"""
    task = Task(1, arrival_time=0, processing_time=5,
                priority=Priority.HIGH, deadline=10)
    task.completion_time = 8
    assert task.meets_deadline() == True

    task.completion_time = 12
    assert task.meets_deadline() == False

# tests/test_algorithms.py
def test_spt_selects_shortest():
    """Test SPT selects task with shortest processing time"""
    tasks = [
        Task(1, 0, 5, Priority.HIGH, 10),
        Task(2, 0, 3, Priority.HIGH, 10),  # Shortest
        Task(3, 0, 7, Priority.HIGH, 10),
    ]

    scheduler = SPT_Scheduler(tasks, num_machines=1)
    selected = scheduler.select_task(tasks)
    assert selected.id == 2

def test_edf_respects_deadlines():
    """Test EDF selects earliest deadline"""
    tasks = [
        Task(1, 0, 5, Priority.HIGH, 15),
        Task(2, 0, 5, Priority.HIGH, 10),  # Earliest
        Task(3, 0, 5, Priority.HIGH, 20),
    ]

    scheduler = EDF_Scheduler(tasks, num_machines=1)
    selected = scheduler.select_task(tasks)
    assert selected.id == 2

def test_dpe_elevation_logic():
    """Test DPE elevates low-priority tasks"""
    tasks = [
        Task(1, arrival_time=0, processing_time=5,
             priority=Priority.LOW, deadline=10),
    ]

    scheduler = DPE_Scheduler(tasks, num_machines=1, alpha=0.5)
    scheduler.current_time = 6  # Pressure = 6/10 = 0.6 > 0.5

    effective = scheduler.get_effective_priority(tasks[0])
    assert effective == Priority.HIGH  # Should be elevated

# tests/test_integration.py
def test_full_simulation_light_load():
    """Test complete simulation run"""
    from scenarios import get_all_scenarios

    scenarios = get_all_scenarios()
    light_load = scenarios[0]  # "Light Load" scenario

    scheduler = EDF_Scheduler(light_load['tasks'],
                              light_load['num_machines'])
    scheduler.run()

    # All tasks should complete
    assert all(task.completion_time is not None for task in scheduler.tasks)

    # Light load should have high success rate
    success = sum(1 for task in scheduler.tasks if task.meets_deadline())
    assert success / len(scheduler.tasks) >= 0.8
```

**Requirements file for testing**:
```
# requirements-dev.txt
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-xdist>=3.0.0  # Parallel test execution
hypothesis>=6.0.0     # Property-based testing
```

#### Task 3.2: Configure Pytest

```python
# tests/conftest.py
import pytest
from simple_simulator import Task, Priority

@pytest.fixture
def sample_tasks():
    """Fixture providing standard test tasks"""
    return [
        Task(1, arrival_time=0, processing_time=3, priority=Priority.HIGH, deadline=10),
        Task(2, arrival_time=1, processing_time=5, priority=Priority.LOW, deadline=15),
        Task(3, arrival_time=2, processing_time=2, priority=Priority.HIGH, deadline=12),
    ]

@pytest.fixture
def simple_scenario():
    """Fixture providing simple test scenario"""
    return {
        'name': 'Test Scenario',
        'tasks': [
            Task(1, 0, 3, Priority.HIGH, 10),
            Task(2, 0, 5, Priority.LOW, 15),
        ],
        'num_machines': 2
    }
```

```ini
# pytest.ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    --verbose
    --cov=.
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=70
```

#### Task 3.3: CI/CD Setup

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.8', '3.9', '3.10', '3.11']

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt

    - name: Run linters
      run: |
        pip install flake8 black
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        black --check .

    - name: Run tests
      run: |
        pytest --cov=. --cov-report=xml --cov-report=term

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella

  build:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v3

    - name: Build package
      run: |
        python -m pip install --upgrade pip
        pip install build
        python -m build
```

### Phase 5: Professional Tooling (Parallel with Phase 4)

#### Task 3.4: Create CLI Interface

```python
# cli.py
"""
Command-line interface for PySchedule
"""
import click
from pathlib import Path
from algorithms import get_all_algorithms
from scenarios import get_all_scenarios
from runner import ExperimentRunner
from visualizer import generate_all_gantt_charts, generate_all_aggregate_visualizations

@click.group()
@click.version_option(version='1.0.0')
def cli():
    """PySchedule: Real-Time Scheduling Research Toolkit

    A discrete-event simulation framework for evaluating real-time
    scheduling algorithms with priorities and deadlines.
    """
    pass

@cli.command()
@click.option('--scenario', '-s', help='Scenario name (e.g., "Light Load")')
@click.option('--algorithm', '-a', help='Algorithm name (e.g., "EDF")')
@click.option('--machines', '-m', type=int, help='Number of machines (overrides scenario default)')
@click.option('--output', '-o', type=click.Path(), help='Output file for results')
@click.option('--verbose', '-v', is_flag=True, help='Verbose output')
def run(scenario, algorithm, machines, output, verbose):
    """Run a single simulation experiment"""

    scenarios = get_all_scenarios()
    algorithms = get_all_algorithms()

    # Find scenario
    if scenario:
        scenario_dict = next((s for s in scenarios if s['name'] == scenario), None)
        if not scenario_dict:
            click.echo(f"Error: Scenario '{scenario}' not found")
            click.echo(f"Available: {', '.join(s['name'] for s in scenarios)}")
            return
    else:
        click.echo("Available scenarios:")
        for s in scenarios:
            click.echo(f"  - {s['name']}")
        return

    # Find algorithm
    if algorithm:
        if algorithm not in algorithms:
            click.echo(f"Error: Algorithm '{algorithm}' not found")
            click.echo(f"Available: {', '.join(algorithms.keys())}")
            return
    else:
        click.echo("Available algorithms:")
        for name in algorithms.keys():
            click.echo(f"  - {name}")
        return

    # Override machines if specified
    if machines:
        scenario_dict['num_machines'] = machines

    # Run experiment
    click.echo(f"Running: {scenario} with {algorithm}")
    runner = ExperimentRunner()
    result = runner.run_experiment(scenario_dict, algorithm, algorithms[algorithm])

    # Display results
    click.echo("\nResults:")
    click.echo(f"  Total tasks: {result['total_tasks']}")
    click.echo(f"  Success rate: {result['success_rate']:.1%}")
    click.echo(f"  High-priority success: {result['high_priority_success']:.1%}")
    click.echo(f"  Low-priority success: {result['low_priority_success']:.1%}")
    click.echo(f"  Fairness score: {result['fairness_score']:.3f}")

    if output:
        import json
        Path(output).write_text(json.dumps(result, indent=2))
        click.echo(f"\nResults saved to: {output}")

@cli.command()
@click.option('--output', '-o', default='results/all_experiments.csv',
              type=click.Path(), help='Output CSV file')
def run_all(output):
    """Run all experiments (24 scenarios Ã— 7 algorithms = 168 total)"""

    click.echo("Running comprehensive experimental suite...")
    click.echo("This will run 168 experiments (24 scenarios Ã— 7 algorithms)")

    from runner import run_all_experiments

    with click.progressbar(length=168, label='Progress') as bar:
        # This would need modification to run_all_experiments to support progress callback
        results = run_all_experiments()
        bar.update(168)

    click.echo(f"\nResults saved to: {output}")

@cli.command()
@click.option('--gantt/--no-gantt', default=True, help='Generate Gantt charts')
@click.option('--aggregate/--no-aggregate', default=True, help='Generate aggregate visualizations')
@click.option('--output-dir', '-o', default='visualizations/',
              type=click.Path(), help='Output directory')
def visualize(gantt, aggregate, output_dir):
    """Generate visualizations from experiment results"""

    Path(output_dir).mkdir(exist_ok=True)

    if gantt:
        click.echo("Generating Gantt charts...")
        with click.progressbar(length=168, label='Gantt charts') as bar:
            generate_all_gantt_charts()
            bar.update(168)

    if aggregate:
        click.echo("Generating aggregate visualizations...")
        generate_all_aggregate_visualizations()

    click.echo(f"\nVisualizations saved to: {output_dir}")

@cli.command()
def list_scenarios():
    """List all available test scenarios"""

    scenarios = get_all_scenarios()

    categories = {
        'Basic': scenarios[0:4],
        'Challenge': scenarios[4:9],
        'Extreme': scenarios[9:14],
        'Advanced': scenarios[14:19],
        'Specialized': scenarios[19:24],
    }

    for category, items in categories.items():
        click.echo(f"\n{category}:")
        for s in items:
            click.echo(f"  - {s['name']}: {s['description']}")

@cli.command()
def list_algorithms():
    """List all available scheduling algorithms"""

    algorithms = get_all_algorithms()

    click.echo("Available algorithms:\n")

    descriptions = {
        'SPT': 'Shortest Processing Time First',
        'EDF': 'Earliest Deadline First',
        'Priority-First': 'Static Priority with EDF tie-breaking',
        'DPE (Î±=0.3)': 'Dynamic Priority Elevation (conservative)',
        'DPE (Î±=0.5)': 'Dynamic Priority Elevation (balanced)',
        'DPE (Î±=0.7)': 'Dynamic Priority Elevation (default)',
        'DPE (Î±=0.9)': 'Dynamic Priority Elevation (aggressive)',
    }

    for name in algorithms.keys():
        desc = descriptions.get(name, 'No description')
        click.echo(f"  {name}: {desc}")

@cli.command()
@click.argument('config_file', type=click.Path(exists=True))
def run_config(config_file):
    """Run experiments from configuration file"""

    import yaml

    with open(config_file) as f:
        config = yaml.safe_load(f)

    click.echo(f"Running experiments from: {config_file}")
    # Implementation depends on config format

if __name__ == '__main__':
    cli()
```

**Usage examples**:
```bash
# List available scenarios and algorithms
pyschedule list-scenarios
pyschedule list-algorithms

# Run single experiment
pyschedule run --scenario "Light Load" --algorithm "EDF"

# Run with custom machine count
pyschedule run -s "Heavy Load" -a "DPE (Î±=0.5)" -m 4

# Run all experiments
pyschedule run-all --output results/full_suite.csv

# Generate visualizations
pyschedule visualize --gantt --aggregate
```

#### Task 3.5: Configuration System

```yaml
# config.yaml
# PySchedule Configuration File

simulation:
  # Default number of machines if not specified in scenario
  default_machines: 2

  # Enable detailed logging
  verbose: false

  # Random seed for reproducibility (if needed for future extensions)
  random_seed: null

algorithms:
  # DPE alpha values to test
  dpe_alpha_values: [0.3, 0.5, 0.7, 0.9]

  # Custom algorithm parameters (future extension)
  custom_params: {}

output:
  # Directory for CSV results
  results_dir: ./results

  # Directory for visualizations
  visualizations_dir: ./visualizations

  # Export formats
  formats:
    - csv
    - json  # Optional: also export as JSON

  # Visualization settings
  visualization:
    dpi: 300  # High-DPI for publications
    format: png
    style: seaborn  # matplotlib style
    figsize: [12, 8]

experiments:
  # Which scenarios to run (empty = all)
  scenarios: []

  # Which algorithms to run (empty = all)
  algorithms: []

  # Enable parallel execution
  parallel: false

  # Number of parallel workers
  workers: 4

logging:
  level: INFO  # DEBUG, INFO, WARNING, ERROR
  format: '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
  file: pyschedule.log
```

```python
# config_loader.py
"""Configuration management for PySchedule"""
import yaml
from pathlib import Path
from typing import Dict, Any

class Config:
    """Configuration manager"""

    DEFAULT_CONFIG_PATH = Path('config.yaml')

    def __init__(self, config_path: Path = None):
        self.config_path = config_path or self.DEFAULT_CONFIG_PATH
        self.data = self._load_config()

    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from YAML file"""
        if not self.config_path.exists():
            return self._default_config()

        with open(self.config_path) as f:
            return yaml.safe_load(f)

    def _default_config(self) -> Dict[str, Any]:
        """Return default configuration"""
        return {
            'simulation': {'default_machines': 2, 'verbose': False},
            'algorithms': {'dpe_alpha_values': [0.3, 0.5, 0.7, 0.9]},
            'output': {
                'results_dir': './results',
                'visualizations_dir': './visualizations',
                'visualization': {'dpi': 300, 'format': 'png'}
            }
        }

    def get(self, key: str, default: Any = None) -> Any:
        """Get configuration value by dot-notation key"""
        keys = key.split('.')
        value = self.data

        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                return default

        return value if value is not None else default

# Global config instance
config = Config()
```

#### Task 3.6: Package Setup

```python
# setup.py
from setuptools import setup, find_packages
from pathlib import Path

# Read README for long description
readme = Path('README.md').read_text(encoding='utf-8')

setup(
    name='pyschedule-rt',
    version='1.0.0',
    description='Real-Time Scheduling Research Toolkit',
    long_description=readme,
    long_description_content_type='text/markdown',
    author='Your Name',
    author_email='your.email@example.com',
    url='https://github.com/yourusername/pyschedule',
    license='MIT',

    packages=find_packages(exclude=['tests', 'tests.*', 'docs']),

    install_requires=[
        'matplotlib>=3.5.0',
        'pandas>=1.3.0',
        'numpy>=1.21.0',
        'click>=8.0.0',
        'pyyaml>=6.0',
    ],

    extras_require={
        'dev': [
            'pytest>=7.0.0',
            'pytest-cov>=4.0.0',
            'pytest-xdist>=3.0.0',
            'black>=22.0.0',
            'flake8>=4.0.0',
            'mypy>=0.950',
        ],
        'docs': [
            'sphinx>=4.5.0',
            'sphinx-rtd-theme>=1.0.0',
        ],
    },

    entry_points={
        'console_scripts': [
            'pyschedule=cli:cli',
        ],
    },

    classifiers=[
        'Development Status :: 4 - Beta',
        'Intended Audience :: Science/Research',
        'Topic :: Scientific/Engineering',
        'License :: OSI Approved :: MIT License',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.8',
        'Programming Language :: Python :: 3.9',
        'Programming Language :: Python :: 3.10',
        'Programming Language :: Python :: 3.11',
    ],

    python_requires='>=3.8',

    keywords='scheduling real-time simulation algorithms research',

    project_urls={
        'Bug Reports': 'https://github.com/yourusername/pyschedule/issues',
        'Source': 'https://github.com/yourusername/pyschedule',
        'Documentation': 'https://pyschedule.readthedocs.io',
    },
)
```

```
# requirements.txt
matplotlib>=3.5.0
pandas>=1.3.0
numpy>=1.21.0
click>=8.0.0
pyyaml>=6.0

# requirements-dev.txt
-r requirements.txt
pytest>=7.0.0
pytest-cov>=4.0.0
pytest-xdist>=3.0.0
black>=22.0.0
flake8>=4.0.0
mypy>=0.950
hypothesis>=6.0.0
```

**Installation**:
```bash
# Development installation
pip install -e .

# With dev dependencies
pip install -e ".[dev]"

# Build and install
python -m build
pip install dist/pyschedule_rt-1.0.0-py3-none-any.whl
```

---

## ðŸ“š Sprint 4: Research Enhancement & Polish (4-6 hours)
**Priority**: Medium impact, adds academic credibility

### Phase 6: Research Documentation

#### Task 4.1: Create docs/RESEARCH.md

```markdown
# Research Background

## Overview

This toolkit implements and evaluates real-time scheduling algorithms for systems with mixed-priority workloads and deadline constraints. The focus is on understanding trade-offs between efficiency (maximizing overall deadline satisfaction) and fairness (preventing starvation of low-priority tasks).

## Theoretical Foundation

### Real-Time Scheduling

Real-time systems have **timing correctness** requirements beyond functional correctness. A result is only correct if produced within specified time bounds (deadlines).

**Key Concepts**:
- **Hard real-time**: Missing deadlines causes system failure (e.g., aircraft control)
- **Soft real-time**: Deadline misses degrade quality (e.g., video streaming)
- **Periodic tasks**: Execute at regular intervals
- **Aperiodic tasks**: Sporadic or event-driven execution

### Classical Results

#### Liu & Layland (1973): Rate-Monotonic Analysis
- **Problem**: Schedule periodic tasks on single processor
- **Result**: Rate-Monotonic (RM) scheduling is optimal for fixed-priority systems
- **Limitation**: No deadline or priority considerations

#### Earliest Deadline First (EDF)
- **Optimality**: EDF is optimal for single-machine scheduling without priorities (Horn, 1974)
- **Complexity**: O(n log n) with priority queue
- **Limitation**: Ignores task priorities, can cause starvation

### Priority Inversion Problem

**Issue**: High-priority tasks blocked by low-priority tasks holding shared resources.

**Example**:
1. Task L (LOW) acquires resource
2. Task H (HIGH) arrives, needs resource â†’ **blocked**
3. Task M (MEDIUM) preempts Task L
4. Result: HIGH blocked by MEDIUM (priority inversion)

**Solutions**:
- **Priority Inheritance**: LOW inherits HIGH's priority while holding resource
- **Priority Ceiling**: Pre-assign resource ceiling priorities
- **Dynamic Priority Elevation (DPE)**: Elevate based on deadline pressure

## Dynamic Priority Elevation (DPE)

### Motivation

Classical algorithms exhibit clear trade-offs:
- **Static Priority**: Guarantees HIGH tasks but starves LOW tasks
- **EDF**: Optimizes deadline satisfaction but ignores priorities
- **Goal**: Adaptive approach balancing both objectives

### Algorithm Specification

**Deadline Pressure**:
```
Ï(t) = (t - t_arrival) / (d - t_arrival)

where:
  t = current time
  t_arrival = task arrival time
  d = task deadline
```

**Effective Priority**:
```
effective_priority(task, t) = {
    HIGH,  if task.priority == HIGH or Ï(t) > Î±
    LOW,   otherwise
}
```

**Scheduling Policy**:
```
select_task(ready_tasks, t) = argmin_{task âˆˆ ready_tasks} (
    effective_priority(task, t),
    deadline(task)
)
```

### Parameter Analysis: Î± Threshold

**Î± âˆˆ [0, 1]**: Controls elevation threshold

| Î± Value | Behavior | Trade-off |
|---------|----------|-----------|
| Î± â†’ 0 | Immediate elevation | Approaches EDF (ignores priorities) |
| Î± = 0.3 | Conservative | High fairness, good efficiency |
| Î± = 0.5 | Balanced | **Pareto optimal** in experiments |
| Î± = 0.7 | Default | Moderate starvation risk |
| Î± â†’ 1 | Delayed elevation | Approaches Priority-First (starvation) |

### Complexity Analysis

**Time Complexity**:
- Per scheduling decision: O(n) for pressure calculation
- Total simulation: O(nÂ² + n log n)
  - Event processing: O(n log n)
  - Scheduling decisions: O(n) decisions Ã— O(n) scan = O(nÂ²)

**Space Complexity**: O(n + m)
- n = number of tasks
- m = number of machines

### Theoretical Properties

**Fairness Guarantee** (when Î± â‰¤ 0.5):
- LOW-priority tasks guaranteed scheduling opportunity
- Elevation occurs when â‰¥50% of available time consumed
- Prevents indefinite starvation

**Efficiency Bound**:
- Worst-case: Degenerates to EDF behavior (Î± â†’ 0)
- Best-case: Maintains Priority-First efficiency (Î± â†’ 1)
- Practical: Î± = 0.5 achieves 71.4% LOW success rate

## Related Work

### Priority-Based Scheduling

1. **Fixed Priority Scheduling** (Liu & Layland, 1973)
   - Assigns static priorities (often by period: shorter period = higher priority)
   - Optimal for certain task models
   - **Limitation**: No dynamic adaptation

2. **Deadline-Driven Scheduling** (Horn, 1974)
   - EDF optimal for single processor
   - **Limitation**: No priority support

3. **Priority Inheritance Protocols** (Sha et al., 1990)
   - Addresses priority inversion in resource sharing
   - **Difference**: Resource-centric vs. deadline-centric elevation

### Adaptive Scheduling

1. **Adaptive Mixed-Criticality Systems** (Vestal, 2007)
   - Mode changes based on criticality level
   - **Similarity**: Both adapt priorities dynamically
   - **Difference**: Criticality levels vs. deadline pressure

2. **Feedback Scheduling** (Lu et al., 2002)
   - Uses control theory for QoS management
   - **Similarity**: Dynamic adjustment
   - **Difference**: Control-theoretic vs. threshold-based

3. **Fair Scheduling** (Stoica et al., 1996)
   - Start-time Fair Queueing for network packets
   - **Similarity**: Fairness objective
   - **Difference**: Network context vs. task scheduling

### Gap Analysis

**Existing Approaches**:
- Static priority: High efficiency, low fairness
- EDF: High efficiency, no priority support
- Priority inheritance: Resource-focused, not deadline-aware

**DPE Contribution**:
- **Combines** priority awareness with deadline urgency
- **Parameterized** fairness-efficiency trade-off (Î±)
- **Practical** threshold-based approach (no complex control theory)

## Experimental Design

### Research Questions

**RQ1**: How does Î± affect fairness-efficiency trade-off?
- **Hypothesis**: Lower Î± increases fairness at efficiency cost
- **Metric**: Pareto frontier of HIGH vs. LOW success rates

**RQ2**: Can DPE prevent low-priority starvation?
- **Hypothesis**: Î± â‰¤ 0.5 prevents starvation in diverse scenarios
- **Metric**: Zero LOW-priority deadline misses

**RQ3**: How do workload characteristics affect algorithm performance?
- **Hypothesis**: Scenario structure determines optimal algorithm
- **Metric**: Success rate heatmap (scenario Ã— algorithm)

### Scenario Design

**24 scenarios across 5 categories**:

1. **Basic** (4): Algorithm validation
   - Light Load, Heavy Load, Batch Arrival, Starvation Test

2. **Challenge** (5): Algorithm differentiation
   - Long High-Priority, Mixed Deadlines, Cascading, Interleaved, Tight Deadlines

3. **Extreme** (5): Stress tests
   - Overload, Impossible Deadlines, SPT Fails, EDF Fails, Priority Starvation

4. **Advanced** (5): Realistic workloads
   - Deadline Clusters, Priority Imbalance, Variable Load, Sparse Arrivals, Deadline Spread

5. **Specialized** (5): Î±-sensitivity
   - Deadline Gradient, Priority Waves, Tight Margins, Overload Recovery, Cascading Failures

### Evaluation Metrics

**Primary Metrics**:
```
Success Rate = (tasks meeting deadline) / (total tasks)

Fairness Score = 1 - |HIGH_success - LOW_success|

Utilization = Î£(task processing times) / (machines Ã— simulation time)
```

**Secondary Metrics**:
- Priority-stratified success rates
- Average completion time
- Deadline tardiness distribution

### Statistical Analysis

**Methods**:
- Pareto frontier identification
- Sensitivity analysis (Î± parameter)
- Scenario-algorithm interaction effects

**Visualization**:
- Gantt charts (168 total)
- Performance heatmaps
- Trade-off scatter plots
- Î±-sensitivity curves

## Results Summary

### Key Findings

**Finding 1: Pareto Optimality**
- Î± âˆˆ {0.3, 0.5} achieve Pareto-optimal trade-off
- 71.4% LOW-priority success rate
- 100% HIGH-priority success in most scenarios

**Finding 2: Starvation Prevention**
- Î± â‰¤ 0.5 prevents starvation in all 24 scenarios
- Î± > 0.5 permits starvation in 3 scenarios (Extreme category)

**Finding 3: Scenario Sensitivity**
- **Light Load**: All algorithms perform well (>90% success)
- **Overload**: Significant algorithm differentiation
- **Starvation Test**: Only DPE (Î± â‰¤ 0.5) prevents LOW-priority failures

**Finding 4: Baseline Comparison**
- SPT: Fast completion, poor deadline satisfaction (42% overall)
- EDF: Best overall success (85%), but ignores priorities
- Priority-First: Perfect HIGH success, LOW starvation (0% LOW success in 5 scenarios)
- DPE (Î±=0.5): Best balance (85% HIGH, 71% LOW)

### Trade-off Characterization

```
                HIGH Success
                     ^
                     |
100% |           â— Priority-First
     |          /
     |        â— DPE (Î±=0.9)
     |       /
     |     â— DPE (Î±=0.7)
 80% |    â— DPE (Î±=0.5) â† **Pareto Optimal**
     |   /
     |  â— DPE (Î±=0.3)    â† **Pareto Optimal**
     | /
     |â— EDF
     |___________________________________> LOW Success
     0%                70%              100%
```

## Implications

### Practical Recommendations

**For Soft Real-Time Systems**:
- Use DPE with Î± = 0.5 for balanced fairness-efficiency
- Monitor deadline pressure in logs to validate Î± choice

**For Hard Real-Time Systems**:
- Consider Î± = 0.3 for maximum safety margin
- Add admission control for overload scenarios

**For Best-Effort Systems**:
- EDF provides optimal deadline satisfaction
- Ignore priorities if fairness not critical

### Future Work

**Algorithmic Extensions**:
1. Multi-level priority support (>2 levels)
2. Adaptive Î± based on workload characteristics
3. Preemption support for long-running tasks

**Theoretical Analysis**:
1. Formal proof of starvation-freedom conditions
2. Competitive ratio analysis vs. optimal offline schedule
3. Worst-case deadline tardiness bounds

**Empirical Evaluation**:
1. Real-world workload traces
2. Comparison with industrial schedulers (Linux CFS, RTOS)
3. Multi-core scheduling extensions

## References

### Foundational Papers

1. **Liu, C. L., & Layland, J. W. (1973)**. "Scheduling Algorithms for Multiprogramming in a Hard-Real-Time Environment." *Journal of the ACM*, 20(1), 46-61.
   - Established Rate-Monotonic and EDF foundations

2. **Horn, W. A. (1974)**. "Some Simple Scheduling Algorithms." *Naval Research Logistics Quarterly*, 21(1), 177-185.
   - Proved EDF optimality for single-machine scheduling

3. **Sha, L., Rajkumar, R., & Lehoczky, J. P. (1990)**. "Priority Inheritance Protocols: An Approach to Real-Time Synchronization." *IEEE Transactions on Computers*, 39(9), 1175-1185.
   - Priority inversion solutions

### Real-Time Systems

4. **Buttazzo, G. C. (2011)**. *Hard Real-Time Computing Systems: Predictable Scheduling Algorithms and Applications* (3rd ed.). Springer.
   - Comprehensive textbook

5. **Davis, R. I., & Burns, A. (2011)**. "A Survey of Hard Real-Time Scheduling for Multiprocessor Systems." *ACM Computing Surveys*, 43(4), 1-44.
   - Multiprocessor scheduling survey

### Adaptive Scheduling

6. **Vestal, S. (2007)**. "Preemptive Scheduling of Multi-criticality Systems with Varying Degrees of Execution Time Assurance." *Proceedings of RTSS*, 239-243.
   - Mixed-criticality systems

7. **Lu, C., Stankovic, J. A., Son, S. H., & Tao, G. (2002)**. "Feedback Control Real-Time Scheduling: Framework, Modeling, and Algorithms." *Real-Time Systems*, 23(1-2), 85-126.
   - Control-theoretic approach

### Fairness in Scheduling

8. **Stoica, I., Abdel-Wahab, H., Jeffay, K., Baruah, S. K., Gehrke, J. E., & Plaxton, C. G. (1996)**. "A Proportional Share Resource Allocation Algorithm for Real-Time, Time-Shared Systems." *Proceedings of RTSS*, 288-299.
   - Fair queueing for real-time

9. **Baruah, S., & Goossens, J. (2004)**. "Scheduling Real-Time Tasks: Algorithms and Complexity." *Handbook of Scheduling: Algorithms, Models, and Performance Analysis*, 28-1 to 28-31.
   - Complexity analysis

### Discrete-Event Simulation

10. **Banks, J., Carson, J. S., Nelson, B. L., & Nicol, D. M. (2010)**. *Discrete-Event System Simulation* (5th ed.). Pearson.
    - Simulation methodology

---

**Document Version**: 1.0
**Last Updated**: 2024
**Author**: [Your Name]
```

#### Task 4.2: Create CITATIONS.bib

```bibtex
% citations.bib
% Bibliography for PySchedule Research Toolkit

@article{liu1973scheduling,
  title={Scheduling algorithms for multiprogramming in a hard-real-time environment},
  author={Liu, Chung Laung and Layland, James W},
  journal={Journal of the ACM (JACM)},
  volume={20},
  number={1},
  pages={46--61},
  year={1973},
  publisher={ACM New York, NY, USA}
}

@article{horn1974simple,
  title={Some simple scheduling algorithms},
  author={Horn, William A},
  journal={Naval Research Logistics Quarterly},
  volume={21},
  number={1},
  pages={177--185},
  year={1974},
  publisher={Wiley Online Library}
}

@article{sha1990priority,
  title={Priority inheritance protocols: An approach to real-time synchronization},
  author={Sha, Lui and Rajkumar, Ragunathan and Lehoczky, John P},
  journal={IEEE Transactions on computers},
  volume={39},
  number={9},
  pages={1175--1185},
  year={1990},
  publisher={IEEE}
}

@book{buttazzo2011hard,
  title={Hard real-time computing systems: predictable scheduling algorithms and applications},
  author={Buttazzo, Giorgio C},
  volume={24},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@article{davis2011survey,
  title={A survey of hard real-time scheduling for multiprocessor systems},
  author={Davis, Robert I and Burns, Alan},
  journal={ACM computing surveys (CSUR)},
  volume={43},
  number={4},
  pages={1--44},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inproceedings{vestal2007preemptive,
  title={Preemptive scheduling of multi-criticality systems with varying degrees of execution time assurance},
  author={Vestal, Steve},
  booktitle={28th IEEE International Real-Time Systems Symposium (RTSS 2007)},
  pages={239--243},
  year={2007},
  organization={IEEE}
}

@article{lu2002feedback,
  title={Feedback control real-time scheduling: Framework, modeling, and algorithms},
  author={Lu, Chenyang and Stankovic, John A and Son, Sang H and Tao, Gang},
  journal={Real-Time Systems},
  volume={23},
  number={1-2},
  pages={85--126},
  year={2002},
  publisher={Springer}
}

@inproceedings{stoica1996proportional,
  title={A proportional share resource allocation algorithm for real-time, time-shared systems},
  author={Stoica, Ion and Abdel-Wahab, Hussein and Jeffay, Kevin and Baruah, Sanjoy K and Gehrke, Johannes E and Plaxton, C Greg},
  booktitle={Proceedings 17th IEEE Real-Time Systems Symposium},
  pages={288--299},
  year={1996},
  organization={IEEE}
}

@incollection{baruah2004scheduling,
  title={Scheduling real-time tasks: Algorithms and complexity},
  author={Baruah, Sanjoy and Goossens, Jo{\"e}l},
  booktitle={Handbook of scheduling: algorithms, models, and performance analysis},
  pages={28--1},
  year={2004},
  publisher={Chapman and Hall/CRC}
}

@book{banks2010discrete,
  title={Discrete-event system simulation},
  author={Banks, Jerry and Carson, John S and Nelson, Barry L and Nicol, David M},
  year={2010},
  publisher={Pearson}
}
```

### Phase 7: Visual Polish

#### Task 4.3: Enhance Visualizations

```python
# visualizer_enhancements.py
"""Enhanced visualization with professional styling"""
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Professional color palette
PALETTE = {
    'high_priority': '#E74C3C',  # Red
    'low_priority': '#3498DB',   # Blue
    'deadline_line': '#2ECC71',  # Green
    'missed': '#95A5A6',         # Gray
    'background': '#ECF0F1',     # Light gray
}

# Set publication-quality defaults
plt.rcParams.update({
    'font.size': 12,
    'font.family': 'serif',
    'font.serif': ['Times New Roman'],
    'figure.dpi': 300,
    'savefig.dpi': 300,
    'savefig.bbox': 'tight',
    'axes.labelsize': 14,
    'axes.titlesize': 16,
    'legend.fontsize': 11,
    'xtick.labelsize': 11,
    'ytick.labelsize': 11,
    'text.usetex': False,  # Set True if LaTeX installed
    'grid.alpha': 0.3,
})

def create_enhanced_gantt(scheduler, title, filename):
    """Create publication-quality Gantt chart"""
    fig, ax = plt.subplots(figsize=(14, 8))

    # Use seaborn style
    sns.set_style("whitegrid")

    # Rest of Gantt chart implementation with enhanced styling
    # ... (existing code with color palette applied)

    plt.savefig(filename, dpi=300, bbox_inches='tight',
                facecolor='white', edgecolor='none')
    plt.close()
```

#### Task 4.4: Create Examples Directory

```python
# examples/basic_usage.py
"""
Basic Usage Example
===================

This example demonstrates the simplest way to use PySchedule.
"""

from simple_simulator import Task, Priority
from algorithms import EDF_Scheduler

# Define tasks
tasks = [
    Task(id=1, arrival_time=0, processing_time=3,
         priority=Priority.HIGH, deadline=10),
    Task(id=2, arrival_time=1, processing_time=5,
         priority=Priority.LOW, deadline=15),
    Task(id=3, arrival_time=2, processing_time=2,
         priority=Priority.HIGH, deadline=12),
]

# Create scheduler
scheduler = EDF_Scheduler(tasks, num_machines=2)

# Run simulation
print("Running simulation...")
scheduler.run()

# Print results
scheduler.print_results()

# Check deadline satisfaction
successful = sum(1 for task in scheduler.tasks if task.meets_deadline())
print(f"\nSuccess rate: {successful}/{len(tasks)} = {successful/len(tasks):.1%}")
```

```python
# examples/custom_algorithm.py
"""
Custom Algorithm Example
========================

This example shows how to implement your own scheduling algorithm.
"""

from simple_simulator import Scheduler, Task, Priority

class SRPT_Scheduler(Scheduler):
    """
    Shortest Remaining Processing Time

    Preemptive variant of SPT that considers remaining time.
    (Note: This requires preemption support - simplified example)
    """

    def select_task(self, ready_tasks):
        """Select task with shortest remaining processing time"""
        if not ready_tasks:
            return None

        # For non-preemptive version, just use processing time
        return min(ready_tasks, key=lambda t: t.processing_time)

# Usage
from scenarios import get_all_scenarios

scenario = get_all_scenarios()[0]  # Light Load
scheduler = SRPT_Scheduler(scenario['tasks'], scenario['num_machines'])
scheduler.run()
scheduler.print_results()
```

```python
# examples/scenario_design.py
"""
Custom Scenario Design Example
===============================

This example shows how to create custom test scenarios.
"""

from simple_simulator import Task, Priority
from algorithms import get_all_algorithms
from runner import ExperimentRunner

# Create custom scenario
custom_scenario = {
    'name': 'Custom Mixed Workload',
    'description': 'Testing behavior with alternating priorities',
    'tasks': [
        Task(1, arrival_time=0, processing_time=4, priority=Priority.HIGH, deadline=10),
        Task(2, arrival_time=1, processing_time=6, priority=Priority.LOW, deadline=20),
        Task(3, arrival_time=2, processing_time=3, priority=Priority.HIGH, deadline=12),
        Task(4, arrival_time=3, processing_time=5, priority=Priority.LOW, deadline=18),
        Task(5, arrival_time=4, processing_time=2, priority=Priority.HIGH, deadline=15),
    ],
    'num_machines': 2
}

# Run with all algorithms
runner = ExperimentRunner()
algorithms = get_all_algorithms()

print(f"Testing scenario: {custom_scenario['name']}")
print(f"Description: {custom_scenario['description']}\n")

for algo_name, algo_class in algorithms.items():
    result = runner.run_experiment(custom_scenario, algo_name, algo_class)
    print(f"{algo_name:20s}: {result['success_rate']:.1%} success")
```

```python
# examples/notebook_example.ipynb
# Jupyter notebook with interactive analysis
# (Content would be in JSON notebook format)
```

#### Task 4.5: Create CONTRIBUTING.md

```markdown
# Contributing to PySchedule

Thank you for considering contributing to PySchedule! This document provides guidelines for contributing to the project.

## Getting Started

1. **Fork the repository** on GitHub
2. **Clone your fork** locally:
   ```bash
   git clone https://github.com/yourusername/pyschedule.git
   cd pyschedule
   ```
3. **Create a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```
4. **Install development dependencies**:
   ```bash
   pip install -e ".[dev]"
   ```

## Development Workflow

### 1. Create a Branch
```bash
git checkout -b feature/your-feature-name
```

Branch naming conventions:
- `feature/` - New features
- `fix/` - Bug fixes
- `docs/` - Documentation improvements
- `test/` - Test additions/improvements
- `refactor/` - Code refactoring

### 2. Make Changes

Follow these guidelines:
- Write clear, descriptive commit messages
- Add tests for new functionality
- Update documentation as needed
- Follow the code style guidelines (below)

### 3. Run Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=. --cov-report=html

# Run specific test file
pytest tests/test_algorithms.py
```

### 4. Format Code
```bash
# Auto-format with black
black .

# Check linting
flake8 .

# Type checking (optional)
mypy .
```

### 5. Submit Pull Request

1. Push your branch to your fork
2. Create a pull request on GitHub
3. Describe your changes clearly
4. Link any related issues

## Code Style Guidelines

### Python Style

Follow PEP 8 with these specifics:
- Line length: 100 characters (not 79)
- Use type hints for all functions
- Use Google-style docstrings

**Example**:
```python
def calculate_pressure(task: Task, current_time: float) -> float:
    """Calculate deadline pressure for a task.

    Args:
        task: The task to calculate pressure for
        current_time: Current simulation time

    Returns:
        Pressure ratio between 0 and infinity

    Raises:
        ValueError: If current_time < task.arrival_time
    """
    # Implementation
```

### Documentation Style

- Use Markdown for documentation files
- Include code examples in docstrings
- Add type hints to all public APIs
- Explain the "why", not just the "what"

### Commit Message Style

Use conventional commits format:
```
type(scope): subject

body (optional)

footer (optional)
```

**Types**:
- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation changes
- `test`: Test additions/changes
- `refactor`: Code refactoring
- `style`: Code style changes (formatting)
- `perf`: Performance improvements

**Examples**:
```
feat(algorithms): add SRPT scheduler implementation

Implements Shortest Remaining Processing Time algorithm
with preemption support.

Closes #42
```

```
fix(simulator): correct deadline pressure calculation

Pressure was incorrect when task already started.
Now returns 0.0 as specified in docs.
```

## Types of Contributions

### 1. Bug Reports

File issues with:
- Clear description of the problem
- Steps to reproduce
- Expected vs. actual behavior
- Python version and OS
- Minimal code example if applicable

### 2. Feature Requests

Propose new features with:
- Use case description
- Proposed API/interface
- Implementation approach (if you have ideas)
- Potential challenges

### 3. Algorithm Implementations

To add a new scheduling algorithm:

1. Create a new class inheriting from `Scheduler`
2. Implement `select_task()` method
3. Add comprehensive docstring with:
   - Algorithm description
   - Policy specification
   - Time complexity
   - Example usage
4. Add unit tests
5. Update `AVAILABLE_ALGORITHMS` dictionary
6. Update documentation

**Template**:
```python
class MyAlgorithm(Scheduler):
    """
    My Algorithm Description

    Policy: [Describe selection policy]
    Complexity: O(?)

    Characteristics:
    - Advantage 1
    - Advantage 2
    - Limitation 1

    Examples:
        >>> tasks = [Task(1, 0, 5, Priority.HIGH, 10)]
        >>> scheduler = MyAlgorithm(tasks, num_machines=1)
        >>> scheduler.run()
    """

    def select_task(self, ready_tasks):
        """Select task according to algorithm policy"""
        # Implementation
```

### 4. Test Scenarios

To add a new test scenario:

1. Add scenario definition to `scenarios.py`
2. Place in appropriate category function
3. Include clear description of what it tests
4. Ensure variety of task parameters
5. Verify it differentiates algorithms

**Template**:
```python
{
    'name': 'Descriptive Name',
    'description': 'What this scenario tests and why it matters',
    'tasks': [
        Task(1, arrival=0, processing=5, priority=Priority.HIGH, deadline=10),
        # ... more tasks with clear rationale
    ],
    'num_machines': 2  # Justify this choice
}
```

### 5. Documentation Improvements

Documentation contributions are highly valued:
- Fix typos or unclear explanations
- Add examples
- Improve API documentation
- Create tutorials
- Translate documentation (future)

### 6. Visualizations

To add or improve visualizations:

1. Create function in `visualizer.py`
2. Follow matplotlib best practices
3. Use project color palette (PALETTE dict)
4. Ensure publication quality (300 DPI)
5. Add docstring with example
6. Include in aggregate visualization functions if appropriate

## Testing Guidelines

### Test Coverage

Aim for >80% code coverage. Priority areas:
1. Core simulation logic (Task, Scheduler, Event)
2. Algorithm selection logic
3. Metrics calculation
4. Edge cases (empty lists, deadline violations, etc.)

### Test Structure

```python
def test_feature_description():
    """Test that [specific behavior] works correctly"""
    # Arrange: Set up test data
    tasks = [Task(1, 0, 5, Priority.HIGH, 10)]

    # Act: Execute the functionality
    scheduler = EDF_Scheduler(tasks, num_machines=1)
    scheduler.run()

    # Assert: Verify expected behavior
    assert scheduler.tasks[0].completion_time is not None
```

### Property-Based Testing

Use `hypothesis` for property-based tests:
```python
from hypothesis import given, strategies as st

@given(st.integers(min_value=1, max_value=100))
def test_task_id_positive(task_id):
    """Task IDs must be positive"""
    task = Task(task_id, 0, 5, Priority.HIGH, 10)
    assert task.id > 0
```

## Performance Considerations

When contributing:
- Profile code if adding complex operations
- Document time/space complexity
- Avoid premature optimization
- Benchmark against existing implementations if replacing code

## Documentation Requirements

All contributions should include:

1. **Code comments**: Explain complex logic
2. **Docstrings**: All public functions/classes
3. **Type hints**: All function signatures
4. **README updates**: If adding new features
5. **Changelog entry**: In CHANGELOG.md (if exists)

## Review Process

Pull requests will be reviewed for:
1. **Functionality**: Does it work as intended?
2. **Tests**: Are there adequate tests?
3. **Documentation**: Is it well-documented?
4. **Style**: Does it follow project conventions?
5. **Performance**: Are there performance implications?

Expect feedback and iteration. This is normal and helps maintain code quality!

## Code of Conduct

Be respectful, constructive, and professional. We aim to maintain a welcoming environment for all contributors.

## Questions?

If you have questions about contributing:
- Open an issue for discussion
- Check existing issues/PRs for similar questions
- Contact [your.email@example.com]

## Recognition

Contributors will be acknowledged in:
- GitHub contributors list
- Project README (for significant contributions)
- Release notes

Thank you for helping improve PySchedule! ðŸš€
```

---

## ðŸ“Š Priority Matrix & Execution Guide

### High Impact, Low Time (Execute First)

| Task | Impact | Time | Status |
|------|--------|------|--------|
| Remove COMP3821 references | ðŸ”´ CRITICAL | 1h | Sprint 1 |
| Professional README | ðŸ”´ HIGH | 2h | Sprint 1-2 |
| Add MIT License | ðŸŸ¢ MEDIUM | 5min | Sprint 1 |
| Create ARCHITECTURE.md | ðŸŸ¡ HIGH | 1.5h | Sprint 2 |
| Add type hints | ðŸŸ¡ MEDIUM | 2h | Sprint 2 |
| GitHub Actions CI | ðŸŸ¡ HIGH | 1h | Sprint 3 |

### High Impact, Medium Time (Execute Second)

| Task | Impact | Time | Status |
|------|--------|------|--------|
| Basic test suite | ðŸŸ¡ HIGH | 3h | Sprint 3 |
| CLI interface | ðŸŸ¡ MEDIUM | 2h | Sprint 3 |
| API_REFERENCE.md | ðŸŸ¢ MEDIUM | 2h | Sprint 2 |
| RESEARCH.md | ðŸŸ¢ HIGH | 2h | Sprint 4 |
| Enhanced visualizations | ðŸŸ¢ MEDIUM | 2h | Sprint 4 |
| Examples directory | ðŸŸ¢ MEDIUM | 2h | Sprint 4 |

### Medium Impact, High Time (Optional)

| Task | Impact | Time | Status |
|------|--------|------|--------|
| Comprehensive tests (>80%) | ðŸŸ¢ MEDIUM | 4h | Optional |
| Jupyter notebooks | ðŸŸ¢ LOW | 3h | Optional |
| GitHub Pages docs | ðŸŸ¢ LOW | 4h | Optional |
| Docker support | ðŸŸ¢ LOW | 2h | Optional |

---

## âœ… Success Criteria

### Must Have (Portfolio Ready)
- âœ… Zero COMP3821 references
- âœ… Professional README with badges
- âœ… MIT License
- âœ… Type hints and docstrings
- âœ… ARCHITECTURE.md
- âœ… Basic test suite
- âœ… GitHub Actions CI
- âœ… CLI interface

### Should Have (Impressive)
- âœ… API_REFERENCE.md
- âœ… RESEARCH.md with citations
- âœ… CONTRIBUTING.md
- âœ… Examples directory
- âœ… Enhanced visualizations
- âœ… 70%+ test coverage

### Nice to Have (Exceptional)
- Jupyter notebooks
- GitHub Pages site
- Docker support
- >85% test coverage

---

## ðŸš€ Quick Start Execution

### Immediate Actions (Can start now)

```bash
# 1. Remove COMP3821 references (30 min)
grep -r "COMP3821\|3821\|Group 5" . --exclude-dir=.git --exclude-dir=.venv > references.txt
# Edit files based on references.txt

# 2. Add MIT License (5 min)
curl -o LICENSE https://raw.githubusercontent.com/licenses/license-templates/master/templates/mit.txt
# Edit with your name and year

# 3. Create requirements files (10 min)
cat > requirements.txt << EOF
matplotlib>=3.5.0
pandas>=1.3.0
numpy>=1.21.0
click>=8.0.0
pyyaml>=6.0
EOF

cat > requirements-dev.txt << EOF
-r requirements.txt
pytest>=7.0.0
pytest-cov>=4.0.0
black>=22.0.0
flake8>=4.0.0
EOF
```

### First Session (2-3 hours)

1. Remove all COMP3821 references (1h)
2. Create new professional README (1.5h)
3. Add MIT License (5min)
4. Git commit checkpoint

### Second Session (4-6 hours)

1. Create ARCHITECTURE.md (1.5h)
2. Add type hints and improve docstrings (2h)
3. Create API_REFERENCE.md (2h)
4. Git commit checkpoint

### Third Session (6-8 hours)

1. Create basic test suite (3h)
2. Setup GitHub Actions CI (1h)
3. Create CLI interface (2h)
4. Setup.py and package structure (1h)
5. Git commit checkpoint

### Fourth Session (4-6 hours)

1. Create RESEARCH.md with citations (2h)
2. Enhance visualizations (2h)
3. Create examples/ directory (2h)
4. Create CONTRIBUTING.md (1h)
5. Final review and polish

---

## ðŸ“ˆ Expected Outcomes

### For Internship Applications

**Technical Depth**:
- âœ… Advanced algorithms (DPE with Î±-parameterization)
- âœ… System design (discrete-event simulation architecture)
- âœ… Performance analysis (complexity, trade-offs)

**Software Engineering**:
- âœ… Clean code (type hints, docstrings, linting)
- âœ… Testing (pytest, CI/CD, coverage)
- âœ… Documentation (comprehensive, multi-audience)
- âœ… Tooling (CLI, config, package management)

**Research Skills**:
- âœ… Literature review (citations, related work)
- âœ… Experimental design (24 scenarios, systematic)
- âœ… Quantitative analysis (metrics, Pareto frontiers)
- âœ… Communication (visualizations, clear writing)

### Talking Points for Interviews

1. **Project Evolution**: "I transformed an academic project into a professional open-source research toolkit, demonstrating initiative and growth mindset."

2. **Technical Depth**: "Implemented 8 scheduling algorithm variants with formal complexity analysis and systematic experimental evaluation."

3. **Software Engineering**: "Added comprehensive testing infrastructure, CI/CD pipeline, and CLI interface to make it production-ready."

4. **Research Skills**: "Conducted rigorous experimental analysis across 24 scenarios, identified Pareto-optimal configurations, and documented findings with academic citations."

5. **Problem Solving**: "Addressed the fairness-efficiency trade-off in priority scheduling through adaptive threshold-based elevation."

---

**Document Version**: 1.0
**Generated**: [Current Date]
**Estimated Total Time**: 16-23 hours
**Priority**: Execute Sprint 1 immediately, then Sprint 2-3 for maximum impact
